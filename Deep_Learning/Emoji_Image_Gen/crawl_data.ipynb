{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb050b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "WEBDRIVER_DELAY_TIME_INT = 20\n",
    "TIMEOUT_INT = 20\n",
    "CHROMEDRIVER_PATH = '/usr/bin/chromedriver'\n",
    "\n",
    "\n",
    "def get_chrome_options():\n",
    "    \"\"\" Set up Chrome options for Selenium WebDriver.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Enables headless mode\n",
    "    # Avoid sandbox issues in some environments\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    # Handles insufficient /dev/shm space\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"window-size=1920x1080\")  # Set window size\n",
    "    return options\n",
    "\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\" Initialize the Selenium WebDriver with Chrome options.\"\"\"\n",
    "    service = Service(executable_path=CHROMEDRIVER_PATH)\n",
    "    chrome_options = get_chrome_options()\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    driver.implicitly_wait(TIMEOUT_INT)  # Implicit wait for elements\n",
    "    return driver\n",
    "\n",
    "\n",
    "# Example usage\n",
    "driver = initialize_driver()\n",
    "wait = WebDriverWait(driver, WEBDRIVER_DELAY_TIME_INT)  # Explicit wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_links_from_page(page_url, driver):\n",
    "    driver.get(page_url)\n",
    "    try:\n",
    "        container = wait.until(EC.presence_of_element_located(\n",
    "            (By.CSS_SELECTOR, \"div.FS5UE28h.container\")\n",
    "        ))\n",
    "        image_items = wait.until(EC.presence_of_all_elements_located(\n",
    "            (By.CSS_SELECTOR, \"div.LQY5mtmC div.aLnnpRah.text-center\"))\n",
    "        )\n",
    "\n",
    "        image_links = []\n",
    "        for img_elem in image_items:\n",
    "            img_div = img_elem.find_element(\n",
    "                By.CSS_SELECTOR, \"div.Mw1EAtrx img, img\")\n",
    "\n",
    "            img_url = img_div.get_attribute(\"src\")\n",
    "            img_title = img_div.get_attribute(\"title\")\n",
    "            if img_url:\n",
    "                image_links.append((img_url, img_title))\n",
    "\n",
    "        return image_links\n",
    "    except Exception as e:\n",
    "        print(f\"Error while trying to extract images: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def hash_image_content(url):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            return hashlib.md5(response.content).hexdigest()\n",
    "        else:\n",
    "            print(\n",
    "                f\"Error downloading image from {url}; status: {response.status_code}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error with the image download for {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_webp_to_jpg(webp_data):\n",
    "    try:\n",
    "        img = Image.open(BytesIO(webp_data))\n",
    "        if img.format == 'WEBP':\n",
    "            if img.mode == 'RGBA':\n",
    "                img = img.convert('RGB')\n",
    "            buffer = BytesIO()\n",
    "            img.save(buffer, format=\"JPEG\")\n",
    "            return buffer.getvalue()\n",
    "        else:\n",
    "            return webp_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting WebP to JPG: {e}\")\n",
    "        return webp_data\n",
    "\n",
    "\n",
    "def download_image(img_url, img_name, folder_path):\n",
    "    try:\n",
    "        response = requests.get(img_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            img_path = os.path.join(folder_path, f\"{img_name}\")\n",
    "            img_data = convert_webp_to_jpg(response.content)\n",
    "            with open(img_path, \"wb\") as f:\n",
    "                f.write(img_data)\n",
    "        else:\n",
    "            print(\n",
    "                f\"Error downloading image from {img_url}; status: {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error with the image download for {img_url}: {e}\")\n",
    "\n",
    "\n",
    "def process_image_page(image_url, img_title, folder_path, idx, tag, seen_hashes):\n",
    "    img_hash = hash_image_content(image_url)\n",
    "    if img_hash and img_hash not in seen_hashes:\n",
    "        seen_hashes.add(img_hash)\n",
    "        new_file_name = f\"{tag}_{idx:07d}.jpg\"\n",
    "        download_image(image_url, new_file_name, folder_path)\n",
    "        metadata = {\n",
    "            \"file_name\": new_file_name,\n",
    "            \"image_url\": image_url,\n",
    "            \"image_title\": img_title,\n",
    "            \"tag\": tag\n",
    "        }\n",
    "        return metadata\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def loop_over_pages(base_url, tags, total_pages, driver, folder_path):\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    all_metadata = []\n",
    "    seen_hashes = set()\n",
    "\n",
    "    for tag in tags:\n",
    "        all_images = []\n",
    "\n",
    "        for page in tqdm(range(1, total_pages + 1), desc=f\"Extracting Images for {tag}\", unit=\"page\"):\n",
    "            page_url = f\"{base_url}/emoji-list/tag/{tag}?page={page}\"\n",
    "            images = get_image_links_from_page(page_url, driver)\n",
    "            all_images.extend(images)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        metadata_list = []\n",
    "        for idx, (img_url, img_title) in enumerate(all_images, start=1):\n",
    "            metadata = process_image_page(\n",
    "                img_url, img_title, folder_path, idx, tag, seen_hashes)\n",
    "            if metadata:\n",
    "                metadata_list.append(metadata)\n",
    "\n",
    "        all_metadata.extend(metadata_list)\n",
    "\n",
    "    return all_metadata\n",
    "\n",
    "\n",
    "def save_metadata(metadata_list, metadata_file):\n",
    "    df = pd.DataFrame(metadata_list)\n",
    "    df.to_csv(metadata_file, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644cf117",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"crawled_data\", exist_ok=True)\n",
    "folder_path = os.path.join(\"crawled_data\", \"images\")\n",
    "metadata_file = os.path.join(\"crawled_data\", \"metadata.csv\")\n",
    "\n",
    "base_url = \"https://discords.com\"\n",
    "tags = [\"Panda\"]\n",
    "total_pages = 1000\n",
    "\n",
    "metadata_list = loop_over_pages(\n",
    "    base_url, tags, total_pages, driver, folder_path)\n",
    "save_metadata(metadata_list, metadata_file)\n",
    "\n",
    "print(\"Start downloading images...\")\n",
    "with tqdm(total=len(metadata_list), desc=\"Downloading Images\", unit=\"image\") as pbar:\n",
    "    for metadata in metadata_list:\n",
    "        img_url = metadata['image_url']\n",
    "        file_name = metadata['file_name']\n",
    "        download_image(img_url, file_name, folder_path)\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"Download images completed.\")\n",
    "\n",
    "total_crawled_images = len(os.listdir(folder_path))\n",
    "print(f\"Total crawled images: {total_crawled_images}.\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7cd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
